{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15af77f3",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f655b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pgmpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4557aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\claud\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pgmpy.models import DiscreteBayesianNetwork\n",
    "from pgmpy.factors.discrete import TabularCPD \n",
    "from pgmpy.inference import VariableElimination\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "125487b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DiscreteBayesianNetwork([('H', 'O'), ('W', 'O'), ('R', 'H', 'W'), ('E', 'H'), ('C','R')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a10e3f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Independente locale:\n",
      "(O ⟂ C, E, R | H, W)\n",
      "(H ⟂ C, W | E, R)\n",
      "(W ⟂ C, H, E, R)\n",
      "(R ⟂ E, W | C)\n",
      "(E ⟂ C, W, R)\n",
      "(C ⟂ E, W)\n"
     ]
    }
   ],
   "source": [
    "print(\"Independente locale:\")\n",
    "print(model.local_independencies('O'))\n",
    "print(model.local_independencies('H'))\n",
    "print(model.local_independencies('W'))\n",
    "print(model.local_independencies('R'))\n",
    "print(model.local_independencies('E'))\n",
    "print(model.local_independencies('C'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a3c63e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpd_o = TabularCPD(variable='O', variable_card=2, values=[[0.3], [0.7]])\n",
    "cpd_H = TabularCPD(variable='H', variable_card=2,\n",
    "                   values=[[0.9, 0.2], [0.1, 0.8]],\n",
    "                   evidence=['O'], evidence_card=[2])\n",
    "cpd_W = TabularCPD(variable='W', variable_card=2,\n",
    "                   values=[[0.1, 0.6], [0.9, 0.4]],\n",
    "                   evidence=['O'], evidence_card=[2])\n",
    "cpd_R = TabularCPD(variable='R', variable_card=2,\n",
    "                   values=[[0.6, 0.9, 0.3, 0.5], \n",
    "                           [0.4, 0.1, 0.7, 0.5]],\n",
    "                   evidence=['H','W'], evidence_card=[2,2])\n",
    "cpd_E = TabularCPD(variable='E', variable_card=2,\n",
    "                   values=[[0.8,0.2], [0.2, 0.8]],\n",
    "                   evidence=['H'], evidence_card=[2])\n",
    "cpd_C = TabularCPD(variable='C', variable_card=2,\n",
    "                   values=[[0.85, 0.40], [0.15, 0.60]],\n",
    "                   evidence=['R'], evidence_card=[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b680400e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pgmpy:Replacing existing CPD for O\n",
      "WARNING:pgmpy:Replacing existing CPD for H\n",
      "WARNING:pgmpy:Replacing existing CPD for W\n",
      "WARNING:pgmpy:Replacing existing CPD for R\n",
      "WARNING:pgmpy:Replacing existing CPD for E\n",
      "WARNING:pgmpy:Replacing existing CPD for C\n"
     ]
    }
   ],
   "source": [
    "model.add_cpds(cpd_o, cpd_H, cpd_W, cpd_R, cpd_E, cpd_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "190776c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "CPD associated with H doesn't have proper parents associated with it.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mModel is consistent:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheck_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pgmpy\\models\\DiscreteBayesianNetwork.py:439\u001b[39m, in \u001b[36mDiscreteBayesianNetwork.check_model\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    437\u001b[39m \u001b[38;5;66;03m# Check if the evidence set of the CPD is same as its parents.\u001b[39;00m\n\u001b[32m    438\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(evidence) != \u001b[38;5;28mset\u001b[39m(parents):\n\u001b[32m--> \u001b[39m\u001b[32m439\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    440\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCPD associated with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m doesn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt have proper parents associated with it.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    441\u001b[39m     )\n\u001b[32m    443\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(cpd.variables) - \u001b[38;5;28mset\u001b[39m(cpd.state_names.keys())) > \u001b[32m0\u001b[39m:\n\u001b[32m    444\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    445\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCPD for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m doesn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt have state names defined for all the variables.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    446\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: CPD associated with H doesn't have proper parents associated with it."
     ]
    }
   ],
   "source": [
    "print(\"Model is consistent:\", model.check_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83e24e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'game_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mgame_model\u001b[49m.check_model()\n\u001b[32m      3\u001b[39m infer = VariableElimination(game_model)\n\u001b[32m      5\u001b[39m jc_HC = infer.query(variables=[\u001b[33m'\u001b[39m\u001b[33mH\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mC\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'game_model' is not defined"
     ]
    }
   ],
   "source": [
    "model.check_model()\n",
    "\n",
    "infer = VariableElimination(model)\n",
    "\n",
    "jc_HC = infer.query(variables=['H', 'C'])\n",
    "jc_EC = infer.query(variables=['E', 'C'])\n",
    "\n",
    "print(\"P(H, C):\")\n",
    "print(jc_HC)\n",
    "print(\"\\nP(E, C):\")\n",
    "print(jc_EC)\n",
    "\n",
    "evidence = {'C': 0}\n",
    "\n",
    "map_HW = infer.map_query(variables=['H', 'W'], evidence=evidence)\n",
    "print(map_HW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3719d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_HW = infer.query(variables=['H', 'W'], evidence=evidence)\n",
    "print(\"\\nP(H, W | C=0):\")\n",
    "print(post_HW)\n",
    "\n",
    "vals = post_HW.values\n",
    "idx = np.argmax(vals)\n",
    "assignment_idx = np.unravel_index(idx, vals.shape)\n",
    "assignment = dict(zip(post_HW.variables, assignment_idx))\n",
    "prob_map = vals[assignment_idx]\n",
    "print(\"\\nMAP assignment (from posterior) and its probability:\")\n",
    "print(assignment, prob_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adcd0ab",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be045652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from hmmlearn import hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc0b82ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [\"Walking\", \"Running\",\"Resting\"]\n",
    "n_states = len(states)\n",
    "\n",
    "observations = [\"Low\", \"Medium\", \"High\"]\n",
    "n_observations = len(observations)\n",
    "\n",
    "start_probability = np.array([1/3, 1/3, 1/3])\n",
    "\n",
    "transition_probability = np.array([ \n",
    "    [0.6, 0.3, 0.1], #Walking\n",
    "    [0.2, 0.7, 0.1], #Running\n",
    "    [0.3, 0.2, 0.5] #Resting\n",
    "])\n",
    "\n",
    "emission_probability = np.array([ \n",
    "    [0.1, 0.7, 0.2], #Walking\n",
    "    [0.05, 0.25, 0.7], #Running\n",
    "    [0.8, 0.15, 0.05] #Resting\n",
    "])\n",
    "\n",
    "model = hmm.CategoricalHMM(n_components=n_states)\n",
    "model.startprob_ = start_probability\n",
    "model.transmat_ = transition_probability\n",
    "model.emissionprob_ = emission_probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8e7273",
   "metadata": {},
   "source": [
    "De la bonus lab5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3309d7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_algorithm(obs_sequence, start_prob, trans_prob, emit_prob): # Defines the custom Forward Algorithm to compute P(O|λ).\n",
    "    T = len(obs_sequence) # Gets the length of the observation sequence.\n",
    "    N = len(start_prob) # Gets the number of hidden states.\n",
    "\n",
    "    alpha = np.zeros((T, N)) # Initializes the alpha matrix (forward probabilities).\n",
    "\n",
    "    for i in range(N): # Initialization step (t=0):\n",
    "        alpha[0][i] = start_prob[i] * emit_prob[i][obs_sequence[0]] # alpha_0(i) = π_i * b_i(o_1).\n",
    "\n",
    "    for t in range(1, T): # Induction step (t=1 to T-1): Iterates through time.\n",
    "        for j in range(N): # Iterates over the current state j.\n",
    "            alpha[t][j] = sum(alpha[t-1][i] * trans_prob[i][j] # Sums over all previous states i: alpha_{t-1}(i) * a_ij.\n",
    "                             for i in range(N)) * emit_prob[j][obs_sequence[t]] # Multiplies by the emission probability b_j(o_{t+1}).\n",
    "def viterbi_algorithm(obs_sequence, start_prob, trans_prob, emit_prob): # Defines the custom Viterbi Algorithm to find the most likely state sequence.\n",
    "    T = len(obs_sequence) # Gets the length of the observation sequence.\n",
    "    N = len(start_prob) # Gets the number of hidden states.\n",
    "\n",
    "    delta = np.zeros((T, N)) # Initializes the delta matrix (maximum path probability).\n",
    "    psi = np.zeros((T, N), dtype=int) # Initializes the psi matrix (backpointers/predecessor states).\n",
    "\n",
    "    for i in range(N): # Initialization step (t=0):\n",
    "        delta[0][i] = start_prob[i] * emit_prob[i][obs_sequence[0]] # delta_0(i) = π_i * b_i(o_1).\n",
    "\n",
    "    for t in range(1, T): # Recursion step (t=1 to T-1): Iterates through time.\n",
    "        for j in range(N): # Iterates over the current state j.\n",
    "            probs = [delta[t-1][i] * trans_prob[i][j] for i in range(N)] # Calculates the path probability coming from each previous state i.\n",
    "            delta[t][j] = max(probs) * emit_prob[j][obs_sequence[t]] # Stores the maximum path probability to state j at time t.\n",
    "            psi[t][j] = np.argmax(probs) # Stores the index of the best predecessor state i.\n",
    "\n",
    "    best_path = np.zeros(T, dtype=int) # Initializes the array to store the final best state sequence.\n",
    "    best_path[T-1] = np.argmax(delta[T-1]) # Termination step: Finds the index of the most likely final state.\n",
    "\n",
    "    for t in range(T-2, -1, -1): # Path Backtracking step: Iterates backwards from T-2 to 0.\n",
    "        best_path[t] = psi[t+1][best_path[t+1]] # Uses the backpointer to recover the previous most likely state.\n",
    "\n",
    "    return best_path # Returns the sequence of hidden state indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2b1f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations_sequence = [\"Medium\",\"High\",\"Low\"]\n",
    "obs_indices = [observations.index(o) for o in observations_sequence]\n",
    "\n",
    "prob = forward_algorithm(obs_indices, start_probability, \n",
    "                        transition_probability, emission_probability)\n",
    "print(\"P(observations) =\", prob)\n",
    "\n",
    "hidden_states = viterbi_algorithm(obs_indices, start_probability,\n",
    "                                  transition_probability, emission_probability)\n",
    "print(\"Most likely states:\", [states[i] for i in hidden_states])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca3bf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations_sequence = [\"Medium\",\"High\",\"Low\"]\n",
    "X = np.array([[observations.index(o)] for o in observations_sequence], dtype=int)\n",
    "logprob = model.score(X)\n",
    "print(\"P(observations) =\", np.exp(logprob))\n",
    "\n",
    "hidden_states = model.predict(X)\n",
    "print(\"Most likely states:\", [states[i] for i in hidden_states])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
